{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dySkCnlWfeos",
        "outputId": "9d2583bb-6971-4742-f17c-d9eaf794c9ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD6zymxwisSW",
        "outputId": "2b29dc32-97dc-43a6-ba33-15254693063c"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'detectenv (Python 3.13.7)' requires the ipykernel package.\n",
            "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/home/peter/projects/MajorProject/app/videoScript/detectenv/bin/python -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import datetime, timezone\n",
        "import http\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ63v0T9iwyo",
        "outputId": "64f32c14-aaf1-42c9-9c17-9b9a31505f81"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ultralytics'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[32m      4\u001b[39m model = YOLO(\u001b[33m\"\u001b[39m\u001b[33myolo11n.pt\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'ultralytics'"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load model\n",
        "model = YOLO(\"yolo11n.pt\")\n",
        "\n",
        "# Train on GPU\n",
        "results = model.train(\n",
        "    data=r\"C:\\Users\\SOHAM\\Downloads\\Major_project-20250818T044734Z-1-001\\Major_project\\yoloo\\data.yaml\",\n",
        "    epochs=100,\n",
        "    imgsz=640,\n",
        "    device=0   # 0 = first GPU\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "H7AKJ3zKk4Vv"
      },
      "outputs": [],
      "source": [
        "new_model = YOLO(r\"C:\\Users\\SOHAM\\Downloads\\Major_project-20250818T044734Z-1-001\\Major_project\\runs\\detect\\train\\weights\\best.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fONBUzgLsemn",
        "outputId": "e1e6530e-e955-4f2e-a4d2-b3f99c8e33bf"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "im = cv2.imread(r'C:\\Users\\SOHAM\\Downloads\\Major_project-20250818T044734Z-1-001\\Major_project\\Testing_images\\panth.jpg')\n",
        "res = new_model.predict(im)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "FtzLcTg6tvaW",
        "outputId": "01231a81-93a4-44a2-c9c6-a358f7e87688"
      },
      "outputs": [],
      "source": [
        "for re in res:\n",
        "    boxes = re.boxes  # Boxes object for bounding box outputs\n",
        "    masks = re.masks  # Masks object for segmentation masks outputs\n",
        "    keypoints = re.keypoints  # Keypoints object for pose outputs\n",
        "    probs = re.probs  # Probs object for classification outputs\n",
        "    obb = re.obb  # Oriented boxes object for OBB outputs\n",
        "    re.show()  # display to screen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final unique animals: {'Panthera_leo': 2}\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from collections import Counter\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# --- settings ---\n",
        "VIDEO = r\"C:\\Users\\SOHAM\\Downloads\\Major_project-20250818T044734Z-1-001\\Major_project\\Testing_images\\video_preview_h264.mp4\"\n",
        "WEIGHTS = r\"C:\\Users\\SOHAM\\Downloads\\Major_project-20250818T044734Z-1-001\\Major_project\\runs\\detect\\train\\weights\\best.pt\"             # your trained model\n",
        "CONF_THRES = 0.5\n",
        "IMG_SIZE = 640\n",
        "TRACKER = \"bytetrack.yaml\"      # robust tracker\n",
        "IOU_MERGE = 0.5                 # merge new track with an existing entity if IoU > this\n",
        "DIST_FRAC = 0.15                # or if centroid distance < this * image diagonal\n",
        "MAX_AGE_SEC = 1.0               # how long (sec) an entity may disappear and still be merged\n",
        "CLASS_WHITELIST = None          # e.g. {\"Panthera_leo\"} to count only lions\n",
        "\n",
        "# --- helpers ---\n",
        "def iou_xyxy(a, b):\n",
        "    ax1, ay1, ax2, ay2 = a\n",
        "    bx1, by1, bx2, by2 = b\n",
        "    inter_x1, inter_y1 = max(ax1, bx1), max(ay1, by1)\n",
        "    inter_x2, inter_y2 = min(ax2, bx2), min(ay2, by2)\n",
        "    iw, ih = max(0, inter_x2 - inter_x1), max(0, inter_y2 - inter_y1)\n",
        "    inter = iw * ih\n",
        "    if inter == 0:\n",
        "        return 0.0\n",
        "    area_a = (ax2 - ax1) * (ay2 - ay1)\n",
        "    area_b = (bx2 - bx1) * (by2 - by1)\n",
        "    return inter / float(area_a + area_b - inter + 1e-6)\n",
        "\n",
        "def centroid(box):\n",
        "    x1, y1, x2, y2 = box\n",
        "    return (0.5*(x1+x2), 0.5*(y1+y2))\n",
        "\n",
        "# --- entity store ---\n",
        "class Entity:\n",
        "    _next_id = 0\n",
        "    def __init__(self, box, frame_idx, class_name, track_id=None):\n",
        "        self.eid = Entity._next_id; Entity._next_id += 1\n",
        "        self.box = box\n",
        "        self.last_frame = frame_idx\n",
        "        self.class_hist = Counter([class_name])\n",
        "        self.canonical = class_name\n",
        "        self.track_ids = set()\n",
        "        if track_id is not None:\n",
        "            self.track_ids.add(int(track_id))\n",
        "    def update(self, box, frame_idx, class_name, track_id=None):\n",
        "        self.box = box\n",
        "        self.last_frame = frame_idx\n",
        "        self.class_hist[class_name] += 1\n",
        "        self.canonical = self.class_hist.most_common(1)[0][0]\n",
        "        if track_id is not None:\n",
        "            self.track_ids.add(int(track_id))\n",
        "\n",
        "# --- main ---\n",
        "model = YOLO(WEIGHTS)\n",
        "\n",
        "cap = cv2.VideoCapture(VIDEO)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
        "w, h = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "diag = (w**2 + h**2) ** 0.5\n",
        "max_age_frames = int(MAX_AGE_SEC * fps)\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "out = cv2.VideoWriter(\"output_video.mp4\", fourcc, fps, (w, h))\n",
        "\n",
        "entities = []  # list[Entity]\n",
        "frame_idx = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame_idx += 1\n",
        "\n",
        "    # Track with ByteTrack\n",
        "    results = model.track(\n",
        "        frame,\n",
        "        imgsz=IMG_SIZE,\n",
        "        conf=CONF_THRES,\n",
        "        tracker=TRACKER,\n",
        "        persist=True,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    annotated = results[0].plot()\n",
        "\n",
        "    boxes = results[0].boxes\n",
        "    if boxes is not None and len(boxes) > 0:\n",
        "        xyxy = boxes.xyxy.cpu().numpy()\n",
        "        clsi = boxes.cls.cpu().numpy().astype(int)\n",
        "        names = [model.names[i] for i in clsi]\n",
        "        tids = boxes.id.cpu().numpy().astype(int).tolist() if boxes.id is not None else [None]*len(xyxy)\n",
        "\n",
        "        for box, name, tid in zip(xyxy, names, tids):\n",
        "            if CLASS_WHITELIST and name not in CLASS_WHITELIST:\n",
        "                continue\n",
        "\n",
        "            # find best entity to merge with\n",
        "            best_e, best_score = None, -1\n",
        "            cx, cy = centroid(box)\n",
        "            for e in entities:\n",
        "                if frame_idx - e.last_frame > max_age_frames:\n",
        "                    continue  # too old to match\n",
        "                iou = iou_xyxy(box, e.box)\n",
        "                ex, ey = centroid(e.box)\n",
        "                dist_ok = ( ((cx-ex)**2 + (cy-ey)**2)**0.5 ) < (DIST_FRAC * diag )\n",
        "                # score: prefer IoU, then distance\n",
        "                score = iou + (0.5 if dist_ok else 0.0)\n",
        "                if score > best_score and (iou >= IOU_MERGE or dist_ok):\n",
        "                    best_e, best_score = e, score\n",
        "\n",
        "            if best_e is None:\n",
        "                # new entity\n",
        "                entities.append(Entity(box, frame_idx, name, tid))\n",
        "            else:\n",
        "                best_e.update(box, frame_idx, name, tid)\n",
        "\n",
        "    # prune very old entities (optional – keeps memory tidy)\n",
        "    entities = [e for e in entities if frame_idx - e.last_frame <= 5*max_age_frames]\n",
        "\n",
        "    # counts by canonical class\n",
        "    counts = Counter()\n",
        "    for e in entities:\n",
        "        if CLASS_WHITELIST and e.canonical not in CLASS_WHITELIST:\n",
        "            continue\n",
        "        counts[e.canonical] += 1\n",
        "    total_unique = sum(counts.values())\n",
        "\n",
        "    # overlay\n",
        "    y = 40\n",
        "    cv2.putText(annotated, f\"Total Unique Animals: {total_unique}\", (20, y),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0,255,0), 4); y += 40\n",
        "    for cls, c in counts.items():\n",
        "        cv2.putText(annotated, f\"{cls}: {c}\", (20, y),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1.1, (0,255,255), 3); y += 32\n",
        "\n",
        "    sendData(species, count, behaviour, latitude, longitude, camera_id)\n",
        "    \n",
        "    cv2.imshow(\"YOLO Video\", annotated)\n",
        "    out.write(annotated)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# final report\n",
        "final_counts = Counter()\n",
        "for e in entities:\n",
        "    if CLASS_WHITELIST and e.canonical not in CLASS_WHITELIST:\n",
        "        continue\n",
        "    final_counts[e.canonical] += 1\n",
        "print(\"Final unique animals:\", dict(final_counts))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import threading\n",
        "\n",
        "from collections import Counter\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# --- settings ---\n",
        "VIDEO = r\"C:\\Users\\SOHAM\\Downloads\\Major_project-20250818T044734Z-1-001\\Major_project\\Testing_images\\video_preview_h264.mp4\"\n",
        "WEIGHTS = r\"C:\\Users\\SOHAM\\Downloads\\Major_project-20250818T044734Z-1-001\\Major_project\\runs\\detect\\train\\weights\\best.pt\"\n",
        "CONF_THRES = 0.5\n",
        "IMG_SIZE = 640\n",
        "TRACKER = \"bytetrack.yaml\"\n",
        "IOU_MERGE = 0.5\n",
        "DIST_FRAC = 0.15\n",
        "MAX_AGE_SEC = 1.0\n",
        "CLASS_WHITELIST = None\n",
        "\n",
        "# --- API settings ---\n",
        "API_ENDPOINT = 'http://127.0.0.1:8000/animals/' # Your API endpoint\n",
        "SEND_INTERVAL_FRAMES = 30 # Send data every 30 frames\n",
        "\n",
        "# --- NEW: Asynchronous data sending function ---\n",
        "async def send_data(session, species, count, behaviour, latitude, longitude, camera_id):\n",
        "    \"\"\"Sends animal data to the API asynchronously.\"\"\"\n",
        "    payload = {\n",
        "        'species': species,\n",
        "        'count': count,\n",
        "        'behaviour': behaviour,\n",
        "        'latitude': latitude,\n",
        "        'longitude': longitude,\n",
        "        'camera_id': camera_id,\n",
        "    }\n",
        "    try:\n",
        "        # The 'json' parameter automatically sets the Content-Type header\n",
        "        async with session.post(API_ENDPOINT, json=payload, timeout=10) as response:\n",
        "            if response.status >= 400:\n",
        "                print(f\"Error sending data for {species}: {response.status} {await response.text()}\")\n",
        "            else:\n",
        "                print(f\"Successfully sent data for {species}: {count}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while sending data for {species}: {e}\")\n",
        "\n",
        "# --- NEW: Thread to run the asyncio event loop ---\n",
        "def run_asyncio_loop(loop):\n",
        "    asyncio.set_event_loop(loop)\n",
        "    loop.run_forever()\n",
        "\n",
        "# --- helpers ---\n",
        "def iou_xyxy(a, b):\n",
        "    ax1, ay1, ax2, ay2 = a; bx1, by1, bx2, by2 = b\n",
        "    inter_x1, inter_y1 = max(ax1, bx1), max(ay1, by1)\n",
        "    inter_x2, inter_y2 = min(ax2, bx2), min(ay2, by2)\n",
        "    iw, ih = max(0, inter_x2 - inter_x1), max(0, inter_y2 - inter_y1)\n",
        "    inter = iw * ih\n",
        "    if inter == 0: return 0.0\n",
        "    area_a = (ax2 - ax1) * (ay2 - ay1)\n",
        "    area_b = (bx2 - bx1) * (by2 - by1)\n",
        "    return inter / float(area_a + area_b - inter + 1e-6)\n",
        "\n",
        "def centroid(box):\n",
        "    x1, y1, x2, y2 = box\n",
        "    return (0.5*(x1+x2), 0.5*(y1+y2))\n",
        "\n",
        "# --- entity store ---\n",
        "class Entity:\n",
        "    _next_id = 0\n",
        "    def __init__(self, box, frame_idx, class_name, track_id=None):\n",
        "        self.eid = Entity._next_id; Entity._next_id += 1\n",
        "        self.box = box; self.last_frame = frame_idx\n",
        "        self.class_hist = Counter([class_name]); self.canonical = class_name\n",
        "        self.track_ids = set()\n",
        "        if track_id is not None: self.track_ids.add(int(track_id))\n",
        "    def update(self, box, frame_idx, class_name, track_id=None):\n",
        "        self.box = box; self.last_frame = frame_idx\n",
        "        self.class_hist[class_name] += 1\n",
        "        self.canonical = self.class_hist.most_common(1)[0][0]\n",
        "        if track_id is not None: self.track_ids.add(int(track_id))\n",
        "\n",
        "# --- main ---\n",
        "# --- NEW: Setup for asyncio in a separate thread ---\n",
        "async_loop = asyncio.new_event_loop()\n",
        "async_thread = threading.Thread(target=run_asyncio_loop, args=(async_loop,), daemon=True)\n",
        "async_thread.start()\n",
        "# We create one session to be reused for all requests for efficiency\n",
        "session_future = asyncio.run_coroutine_threadsafe(aiohttp.ClientSession().__aenter__(), async_loop)\n",
        "session = session_future.result()\n",
        "\n",
        "\n",
        "model = YOLO(WEIGHTS)\n",
        "cap = cv2.VideoCapture(VIDEO)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
        "w, h = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "diag = (w**2 + h**2) ** 0.5\n",
        "max_age_frames = int(MAX_AGE_SEC * fps)\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "out = cv2.VideoWriter(\"output_video.mp4\", fourcc, fps, (w, h))\n",
        "entities = []\n",
        "frame_idx = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret: break\n",
        "    frame_idx += 1\n",
        "\n",
        "    results = model.track(frame, imgsz=IMG_SIZE, conf=CONF_THRES, tracker=TRACKER, persist=True, verbose=False)\n",
        "    annotated = results[0].plot()\n",
        "    boxes = results[0].boxes\n",
        "    if boxes is not None and len(boxes) > 0:\n",
        "        xyxy = boxes.xyxy.cpu().numpy()\n",
        "        clsi = boxes.cls.cpu().numpy().astype(int)\n",
        "        names = [model.names[i] for i in clsi]\n",
        "        tids = boxes.id.cpu().numpy().astype(int).tolist() if boxes.id is not None else [None]*len(xyxy)\n",
        "        for box, name, tid in zip(xyxy, names, tids):\n",
        "            if CLASS_WHITELIST and name not in CLASS_WHITELIST: continue\n",
        "            best_e, best_score = None, -1\n",
        "            cx, cy = centroid(box)\n",
        "            for e in entities:\n",
        "                if frame_idx - e.last_frame > max_age_frames: continue\n",
        "                iou = iou_xyxy(box, e.box)\n",
        "                ex, ey = centroid(e.box)\n",
        "                dist_ok = ( ((cx-ex)**2 + (cy-ey)**2)**0.5 ) < (DIST_FRAC * diag )\n",
        "                score = iou + (0.5 if dist_ok else 0.0)\n",
        "                if score > best_score and (iou >= IOU_MERGE or dist_ok):\n",
        "                    best_e, best_score = e, score\n",
        "            if best_e is None:\n",
        "                entities.append(Entity(box, frame_idx, name, tid))\n",
        "            else:\n",
        "                best_e.update(box, frame_idx, name, tid)\n",
        "\n",
        "    entities = [e for e in entities if frame_idx - e.last_frame <= 5*max_age_frames]\n",
        "    counts = Counter(e.canonical for e in entities if not CLASS_WHITELIST or e.canonical in CLASS_WHITELIST)\n",
        "    total_unique = sum(counts.values())\n",
        "\n",
        "    # --- NEW: Trigger data sending ---\n",
        "    if frame_idx % SEND_INTERVAL_FRAMES == 0 and total_unique > 0:\n",
        "        print(f\"\\n--- Frame {frame_idx}: Sending data ---\")\n",
        "        # --- TO DO: Fill these with actual data ---\n",
        "        behaviour = \"grazing\"\n",
        "        latitude = 19.0760\n",
        "        longitude = 72.8777\n",
        "        camera_id = \"CAM-001\"\n",
        "        \n",
        "        for species, count in counts.items():\n",
        "            # Create a coroutine object for the API call\n",
        "            coro = send_data(session, species, count, behaviour, latitude, longitude, camera_id)\n",
        "            # Submit it to the event loop running in the other thread\n",
        "            asyncio.run_coroutine_threadsafe(coro, async_loop)\n",
        "\n",
        "    # overlay\n",
        "    y = 40\n",
        "    cv2.putText(annotated, f\"Total Unique Animals: {total_unique}\", (20, y),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0,255,0), 4); y += 40\n",
        "    for cls, c in counts.items():\n",
        "        cv2.putText(annotated, f\"{cls}: {c}\", (20, y),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1.1, (0,255,255), 3); y += 32\n",
        "    \n",
        "    cv2.imshow(\"YOLO Video\", annotated)\n",
        "    out.write(annotated)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
        "\n",
        "# --- NEW: Cleanup ---\n",
        "print(\"Closing resources...\")\n",
        "# Close the aiohttp session\n",
        "asyncio.run_coroutine_threadsafe(session.__aexit__(None, None, None), async_loop)\n",
        "# Stop the event loop\n",
        "async_loop.call_soon_threadsafe(async_loop.stop)\n",
        "# Wait for the thread to finish\n",
        "async_thread.join()\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "final_counts = Counter(e.canonical for e in entities if not CLASS_WHITELIST or e.canonical in CLASS_WHITELIST)\n",
        "print(\"Final unique animals:\", dict(final_counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sendData(species, count, behaviour, latitude, longitude, camera_id):\n",
        "    url = 'http://127.0.0.1:8000/animals/'\n",
        "    \n",
        "    # Generate a timezone-aware timestamp in the correct ISO format\n",
        "    # The 'Z' at the end is automatically handled by .isoformat() for UTC times\n",
        "    timestamp_now = datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "    data = {\n",
        "        'species': species,\n",
        "        'count': count,\n",
        "        'behaviour': behaviour,\n",
        "        'latitude': latitude,\n",
        "        'longitude': longitude,\n",
        "        'camera_id': camera_id,\n",
        "        'timestamp': timestamp_now # Use the generated timestamp\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        response = requests.post(url, json=data)\n",
        "        response.raise_for_status() \n",
        "        \n",
        "        print(f\"Success! Status: {response.status_code}\")\n",
        "        print(\"Response JSON:\", response.json())\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        # This part can be improved to show the specific error from Django\n",
        "        if e.response:\n",
        "            print(f\"Error from server: {e.response.status_code}\")\n",
        "            print(\"Details:\", e.response.json())\n",
        "        else:\n",
        "            print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Success! Status: 201\n",
            "Response JSON: {'id': 3, 'species': 'Panthera_leo', 'count': 3, 'behaviour': 'Walking', 'latitude': '12.971600', 'longitude': '77.594600', 'camera_id': 'CAM-001', 'timestamp': '2025-09-10T17:35:36.208660Z'}\n"
          ]
        }
      ],
      "source": [
        "sendData(\"Panthera_leo\", 3, \"Walking\", 12.9716, 77.5946, \"CAM-001\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "detectenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
